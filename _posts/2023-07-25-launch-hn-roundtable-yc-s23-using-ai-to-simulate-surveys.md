---
layout: post
title:  "启动 HN：圆桌讨论（YC S23）- 使用 AI 模拟调查"
author: timshell
description: Roundtable 是一个利用大型语言模型（LLM）进行快速、低成本调查模拟的平台。该平台通过训练 LLM 来模拟人类行为和意见，从而使用户能够在几秒钟内获得调查结果，并快速做出决策。文章介绍了 Roundtable 的功能，包括添加问题和条件以影响调查结果，以及如何通过比较年龄和人口统计数据来验证其准确性。此外，文章还讨论了模型在处理不同人口群体时的偏差，并介绍了如何通过微调来提高模型的代表性。Roundtable 面向中小企业市场，并正在寻求用户反馈以改进其产品。
categories: [ Hacker News ]
image: https://picsum.photos/seed/1690304832/750/500
tags: [seed round]
---

作者: timshell | 发布日期: 2023-07-25 | 评分: 121 | 评论数: 39

**摘要：**

Roundtable 是一个利用大型语言模型（LLM）进行快速、低成本调查模拟的平台。该平台通过训练 LLM 来模拟人类行为和意见，从而使用户能够在几秒钟内获得调查结果，并快速做出决策。文章介绍了 Roundtable 的功能，包括添加问题和条件以影响调查结果，以及如何通过比较年龄和人口统计数据来验证其准确性。此外，文章还讨论了模型在处理不同人口群体时的偏差，并介绍了如何通过微调来提高模型的代表性。Roundtable 面向中小企业市场，并正在寻求用户反馈以改进其产品。

Hi HN, we’re Mayank and Matt of Roundtable (https://roundtable.ai/). We use LLMs to produce cheap, yet surprisingly useful, simulations of surveys. Specifically, we train LLMs on standard, curated survey datasets. This approach allows us to essentially build general-purpose models of human behavior and opinion. We combine this with a nice UI that lets users easily visualize and interpret the results.Surveys are incredibly important for user and market research, but are expensive and take months to design, run, and analyze. By simulating responses, our users can get results in seconds and make decisions faster. See https://roundtable.ai/showcase for a bunch of examples, and https://www.loom.com/share/eb6fb27acebe48839dd561cf1546f131 for a demo video.Our product lets you add questions (e.g. “how old are you”) and conditions (e.g. “is a Hacker News user”) and then see how these affect the survey results. For example, the survey “Are you interested in buying an e-bike?” shows ‘yes’ 28% [1]. But if you narrow it down to people who own a Tesla, ‘yes’ jumps to 52% [2]. Another example: if you survey “where did you learn to code”, the question “how old are you?” makes a dramatic difference—for “45 or older” the answer is 55% “books” [3], but for “younger than 45” it’s 76% “online” [4]. One more: 5% of people answer “legroom” to the question “Which of the following factors is most important for choosing which airline to fly?” [5], and this jumps to 20% when you condition on people over six feet tall [6].You wouldn’t think (well, we didn’t think) that such simulated surveys would work very well, but empirically they work a lot better than expected—we have run many surveys in the wild to validate Roundtable's results (e.g. comparing age demographics to U.S. Census data). We’re still trying to figure out why. We believe that LLMs that are pre-trained on the public Internet have internalized a lot of information/correlations about communities (e.g. Tesla drivers, Hacker News, etc.) and can reasonably approximate their behavior. In any case, researchers are seeing the same things that we are. A nice paper by a BYU group [7] discusses extracting sub-population information from GPT/LLMs. A related paper from Microsoft [8] shows how GPT can simulate different human behaviors. It’s an active research topic, and we hope we can get a sense of the theoretical basis relatively soon.Because these models are primarily trained on Internet data, they start out skewed towards the demographics of heavy Internet users (e.g., high-income, male). We addressed this by fine-tuning GPT on the GSS (General Social Survey [9] - the gold standard of demographic surveys in the US) so our models emulate a more representative U.S. population.We’ve built a transparency feature that shows how similar your survey question is to the training data and thus gives a confidence metric of our accuracy. If you click ‘Investigate Results’, we report the most similar (in terms of cosine distance between LLM embeddings) GSS questions as a way of estimating how much extrapolation / interpolation is going on. This doesn’t quite address the accuracy of the subpopulations / conditioning questions (we are working on this), but we thought we are at a sufficiently advanced point to share what we’ve built with you all.We're graduating PhD students from Princeton University in cognitive science and AI. We ran a ton of surveys and behavioral experiments and were often frustrated with the pipeline. We were looking to leave academia, and saw an opportunity in making the survey pipeline better. User and market research is a big market, and many of the tools and methods the industry uses are clunky and slow. Mayank’s PhD work used large datasets and ML for developing interpretable scientific theories, and Matt’s developed complex experimental software to study coordinated group decision-making. We see Roundtable as operating at the intersection of our interests.We charge per survey. We are targeting small and mid-market businesses who have market research teams, and ask for a minimum subscription amount. Pricing is at the bottom of our home page.We are still in the early stages of building this product, and we’d love for you all to play around with the demo and provide us feedback. Let us know whatever you see - this is our first major endeavor into the private sector from academia, and we’re eager to hear whatever you have to say![1]: https://roundtable.ai/sandbox/e02e92a9ad20fdd517182788f4ae7e...[2]: https://roundtable.ai/sandbox/6b4bf8740ad1945b08c0bf584c84c1...[3] https://roundtable.ai/sandbox/d701556248385d05ce5d26ce7fc776...[4] https://roundtable.ai/sandbox/8bd80babad042cf60d500ca28c40f7...[5] https://roundtable.ai/sandbox/0450d499048c089894c34fba514db4...[6] https://roundtable.ai/sandbox/eeafc6de644632af303896ec19feb6...[7] https://arxiv.org/abs/2209.06899[8] https://openreview.net/pdf?id=eYlLlvzngu[9] https://www.norc.org/research/projects/gss.html

**原文链接**: https://news.ycombinator.com/item?id=36865625

**Hacker News 讨论：**

文章主要讨论了关于使用人工智能模型（如Roundtable）进行市场调研的优缺点和潜在问题。评论者们提出了以下几个关键点：1) 对于AI模型预测结果的准确性存在怀疑，认为其可能无法准确反映人类真实意愿；2) 担心AI模型可能加剧社会不平等，因为模型可能会基于偏见的数据产生偏见的结果；3) 对AI模型的可靠性表示担忧，认为其可能产生误导性或不可靠的结果；4) 认为AI模型可能会减少人与人之间的联系，并质疑其作为替代真实市场调研工具的可行性；5) 提出了一些改进建议，如增加数据验证功能、改进用户体验和提供更好的问题构建工具。

